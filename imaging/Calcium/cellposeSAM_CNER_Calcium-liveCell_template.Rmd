---
title: "cellposeSAM_CNER_Calcium-liveCell"
output: html_document
date: "2025-05-20"
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# I. Load packackes
```{r}
library(devtools)

# Core data manipulation & visualization
library(tidyverse)        # ggplot2, dplyr, purrr, readr, tibble, tidyr, stringr
library(zoo)              # Rolling operations
library(reshape2)         # Data reshaping
library(pheatmap)         # Heatmaps
library(ggdendro)         # Dendrograms
library(viridis)          # Color palettes
library(RColorBrewer)
library(NatParksPalettes)
library(tidyplots)
library(ggpubr)           # Publication-ready plots
library(ggsignif)         # Significance annotations
library(Cairo)            # For cairo_pdf output
library(patchwork)        # Plot layouts
library(cowplot)          # Plot composition
library(gridExtra)        # Layout utilities
library(grid)             # Viewports and custom layout
library(rlang)            # Tidy evaluation tools

# Network analysis
library(igraph)
library(ggraph)
#devtools::install_github("simo-91/CalNetExploreR")
library(CalNetExploreR)

# Signal processing
#library(signal)

# Plot composition
library(gridExtra)
library(grid)
library(cowplot)
library(RColorBrewer)

# PCA visualization
library(factoextra)

library(dplyr)

```

# II. Preprocessing & Analysis
=> cellposeSAM based evaluation %>% into batch dF/F processing script 
=> used cellposeSAM for image segementation and measurement of ROIs
=> cellposeSAM output:
- each row is one soma followed by mean intensities saved across columns 
- each new timepoint is new column 

## IIa. User Input & Configuration
```{r}
# ==========================================================
# CellposeSAM-based Calcium Imaging Batch Analysis Pipeline
# ==========================================================
# This script integrates output from CellposeSAM, processes dF/F traces, 
# binarizes events, computes correlation-based networks (CNER), and 
# extracts per-cell statistics.


# Paths, user-defined parameters, sample/genotype mapping, colors
base_path <- "/Users/felix/HMS Dropbox/Felix Kraus/Felix/Harvard/03_LSD-PD/Microscopy/20250623_diff138_iN_d21_Ctrl-ASAH1_Flou4/cpsam_d21/nd2_labels/"


# genotype map should be a unique file name part, so it can differentiate between conditions etc 
genotype_map <- list(
   "iN_d21_Ctrl_Fed_Fluo4"        = "iN_d21_Controlbasal",
   "iN_d21_Ctrl_100mMKCL_Fluo4"     = "iN_d21_ControlKCL",
   "iN_d21_Ctrl_10µMCQNX_Fluo4"     = "iN_d21_ControlCQNX",
   "iN_d21_ASAH1_Fed_Fluo4"        = "iN_d21_ASAH1basal",
   "iN_d21_ASAH1_100mMKCL_Fluo4"     = "iN_d21_ASAH1KCL",
   "iN_d21_ASAH1_10µMCQNX_Fluo4"     = "iN_d21_ASAH1CQNX"
 )



# Direct mapping (no interpolation)
# Colors auto-generated based on mapping
geno_levels <- unique(unname(genotype_map))
base_colors <- RColorBrewer::brewer.pal(length(geno_levels), "Set2")  
geno_cols <- setNames(base_colors, geno_levels)

stopifnot(length(base_colors) >= length(geno_levels))


# Analysis parameters
baseline_window <- 100        # Rolling window size for baseline (frames). should be maybe 10% of frames to get good avg.
frame_rate      <- 10
smoothing_k     <- NULL          # Optional smoothing over raw intensity traces (frames), set to NULL to disable smoothing
threshold_factor <- 0.4       # Threshold for binarization (fraction of SD)
correlation_threshold <- 0.4  #Correlation threshold for network (used in make_network())
image_dim <- c(1570, 1140)    # width, height in pixels of image. Need to backmap the roi activity network onto the image coordinats 


# define output dirs:
ca_results_dir <- file.path(base_path, "calcium_results")
dir.create(ca_results_dir, recursive = TRUE, showWarnings = FALSE)
```

## IIb. baseline correction, ∆F/F Processing
```{r}
# -----------------------------
# Helper Function – ΔF/F Calculation
# -----------------------------
calculate_dff <- function(trace, window = baseline_window, smoothing_k = NULL, percentile = 0.2) {
  if (!is.null(smoothing_k)) {
    trace <- zoo::rollmean(trace, k = smoothing_k, fill = NA)
  }

  if (length(trace) < window || all(is.na(trace))) {
    return(rep(NA, length(trace)))
  }

  baseline <- zoo::rollapply(trace, width = window,
                              FUN = function(x) quantile(x, probs = percentile, na.rm = TRUE),
                              align = "center", fill = NA, partial = TRUE)

  baseline <- pmax(baseline, 1e-3)  # Avoid division by zero
  dff <- (trace - baseline) / baseline
  pmax(dff, 0)  # Clip negatives
}

# -----------------------------
# Helper Function – Noise Filter + dF/F per File
# -----------------------------
process_pair <- function(centroid_file) {
  intensity_file <- sub("_centroids_valid.csv$", "_intensity.csv", centroid_file)
  if (!file.exists(intensity_file)) return(NULL)

  sample_name <- basename(centroid_file)

  centroids <- read_csv(centroid_file, show_col_types = FALSE) %>%
    mutate(ObjectNumber = as.integer(label), file = sample_name) %>%
    select(file, ObjectNumber, centroid_x, centroid_y)

  intensity <- read_csv(intensity_file, show_col_types = FALSE) %>%
    select(-file)  # Drop 'file' if present

  # --- Compute filtering threshold from first frame
  baseline_avg <- median(as.numeric(intensity[1, -1]), na.rm = TRUE)
  filter_thresh <- 0.3 * baseline_avg

  # --- Apply noise filter: clamp the signal to the threshold
  intensity_filtered <- intensity %>%
   mutate(across(-time, ~pmax(.x, filter_thresh)))

  # --- Calculate dF/F on filtered data
  traces_dff <- intensity_filtered %>%
    mutate(across(-time, ~calculate_dff(.x, window = baseline_window, smoothing_k = smoothing_k)))

  traces_long <- traces_dff %>%
    mutate(ImageNumber = row_number()) %>%
    pivot_longer(cols = -c(time, ImageNumber),
                 names_to = "ObjectNumber",
                 values_to = "Intensity_IntegratedIntensity_Fura",
                 values_drop_na = TRUE) %>%
    mutate(ObjectNumber = as.integer(ObjectNumber),
           file = sample_name)

  list(traces = traces_long, centroids = centroids)
}

# -----------------------------
# Load and Merge All Samples
# -----------------------------
file_list <- list.files(base_path, pattern = "_centroids_valid.csv$", full.names = TRUE)
parsed_data <- map(file_list, process_pair) %>% compact()

combined_df  <- map_dfr(parsed_data, "traces")
centroid_df  <- map_dfr(parsed_data, "centroids")


# -----------------------------
# Initialize Result Lists
# -----------------------------
cor_list <- list()
comm_list <- list()
events_list <- list()
summary_list <- list()
```


## IIc. Trace Plotting (per sample), Correlations, Network plots and Firing Statistics 
```{r}
# -------------------------------------------------
# Trace Plotting (per sample), Correlations, Network plots and Firing Statistics 
# -------------------------------------------------

# --- Setup
trace_dir <- file.path(base_path, "label_traces")
dir.create(trace_dir, recursive = TRUE, showWarnings = FALSE)

all_sample_ids <- unique(combined_df$file)
centroid_df_clean <- centroid_df %>%
  dplyr::mutate(file = as.character(file), ObjectNumber = as.integer(ObjectNumber))

# --- Palettes
corr_palette <- colorRampPalette(rev(RColorBrewer::brewer.pal(11, "RdYlBu")))(100)
node_palette <- colorRampPalette(rev(RColorBrewer::brewer.pal(9, "YlGnBu")))(100)

for (sample_id in all_sample_ids) {
  clean_sample_id <- gsub("_centroids_valid.csv$", "", basename(sample_id))
  output_dir <- file.path(base_path, clean_sample_id)
  dir.create(output_dir, recursive = TRUE, showWarnings = FALSE)

  # --- Merge & process dF/F
  df_sample <- dplyr::filter(combined_df, file == sample_id) %>%
    dplyr::select(-matches("^centroid_")) %>%
    dplyr::left_join(centroid_df_clean, by = c("file", "ObjectNumber")) %>%
    dplyr::group_by(ObjectNumber) %>%
    dplyr::arrange(ImageNumber, .by_group = TRUE) %>%
    dplyr::mutate(
      dF_F = calculate_dff(Intensity_IntegratedIntensity_Fura,
                           window = baseline_window,
                           smoothing_k = smoothing_k,
                           percentile = 0.4),
      dF_F_scaled = dF_F / max(dF_F, na.rm = TRUE),
      dF_F_binary = ifelse(dF_F > threshold_factor * sd(dF_F, na.rm = TRUE), 1, 0),
      spike_amplitude = ifelse(dF_F_binary == 1, dF_F_scaled, NA)
    ) %>%
    dplyr::ungroup()

  # --- Per-ROI trace plots
  roi_ids <- unique(df_sample$ObjectNumber)
  for (i in seq_along(roi_ids)) {
    df_trace <- dplyr::filter(df_sample, ObjectNumber == roi_ids[i])
    p_raw    <- ggplot(df_trace, aes(x = ImageNumber, y = Intensity_IntegratedIntensity_Fura)) + geom_line() + theme_minimal()
    p_scaled <- ggplot(df_trace, aes(x = ImageNumber, y = dF_F_scaled)) + geom_line(color = "dodgerblue") + theme_minimal()
    p_binary <- ggplot(df_trace, aes(x = ImageNumber, y = dF_F_binary)) + geom_step(color = "firebrick2") + theme_minimal()
    ggsave(file.path(trace_dir, paste0(clean_sample_id, "_ROI_", i, ".pdf")),
           p_raw / p_scaled / p_binary, width = 6, height = 6, device = cairo_pdf)
  }

  # --- Binary matrix for correlation
  mat <- df_sample %>%
    dplyr::select(ObjectNumber, ImageNumber, dF_F_binary) %>%
    tidyr::pivot_wider(names_from = ImageNumber, values_from = dF_F_binary) %>%
    dplyr::arrange(ObjectNumber)
  mat_matrix <- as.matrix(dplyr::select(mat, -ObjectNumber))
  rownames(mat_matrix) <- mat$ObjectNumber
  cor_mat <- cor(t(mat_matrix), use = "pairwise.complete.obs")
  cor_mat[!is.finite(cor_mat)] <- 0

  # --- Save correlation heatmap
  pdf(file.path(output_dir, paste0(clean_sample_id, "_CorrelationMatrix.pdf")), width = 6, height = 6)
  pheatmap(cor_mat, clustering_method = "complete", main = "Correlation Matrix", border_color = NA, fontsize = 6)
  dev.off()

  # --- Firing statistics
  group_label <- if (sample_id %in% names(genotype_map)) {
    genotype_map[[sample_id]]
  } else {
    "Unknown"
  }
  
  # Filter invalid-length binary bursts
  df_sample <- df_sample %>%
    dplyr::group_by(ObjectNumber) %>%
    dplyr::arrange(ImageNumber, .by_group = TRUE) %>%
    dplyr::mutate(
      run_id = data.table::rleid(dF_F_binary),
      run_len = ave(dF_F_binary, ObjectNumber, run_id, FUN = length),
      dF_F_binary = ifelse(dF_F_binary == 1 & (run_len < 1 | run_len > 60), 0, dF_F_binary)
    ) %>%
    dplyr::ungroup()
  
  # Recompute rising edge AFTER filtering
  df_sample <- df_sample %>%
    dplyr::group_by(ObjectNumber) %>%
    dplyr::arrange(ImageNumber, .by_group = TRUE) %>%
    dplyr::mutate(rising_edge = dF_F_binary == 1 & lag(dF_F_binary, default = 0) == 0) %>%
    dplyr::ungroup()
  
  # Compute firing stats
  firing_stats <- df_sample %>%
    dplyr::group_by(ObjectNumber) %>%
    dplyr::summarise(
      firing_events   = sum(rising_edge, na.rm = TRUE),
      total_frames    = dplyr::n(),
      active_frames   = sum(dF_F_binary, na.rm = TRUE),
      percent_active  = 100 * active_frames / total_frames,
      spike_amplitude = if (sum(dF_F_binary == 1 & dF_F_scaled > 0.2, na.rm = TRUE) > 0) {
        quantile(dF_F_scaled[dF_F_binary == 1 & dF_F_scaled > 0.2], 0.75, na.rm = TRUE)
      } else {
        NA_real_
      },
      .groups = "drop"
    ) %>%
    dplyr::mutate(
      Sample = sample_id,
      firing_rate_per_min = firing_events / (max(df_sample$ImageNumber, na.rm = TRUE) / (frame_rate * 60)),
      Group = group_label
    )
  
  # Save to list
  events_list[[clean_sample_id]] <- firing_stats
  
  # --- Sample-level summary stats
  n_cells        <- dplyr::n_distinct(df_sample$ObjectNumber)
  n_frames_total <- max(df_sample$ImageNumber, na.rm = TRUE)
  duration_min   <- n_frames_total / (frame_rate * 60)
  
  sample_summary <- firing_stats %>%
    dplyr::summarise(
      Sample                          = clean_sample_id,
      Total_cells                     = n_cells,
      Total_firing_events             = sum(firing_events, na.rm = TRUE),
      Firing_events_per_min           = Total_firing_events / duration_min,
      Firing_events_per_min_norm      = Firing_events_per_min / n_cells,
      Cells_active                    = sum(firing_events > 0, na.rm = TRUE),
      Percent_cells_active            = 100 * Cells_active / n_cells,
      Mean_percent_active_frames      = mean(percent_active, na.rm = TRUE),
      Mean_percent_active_frames_norm = Mean_percent_active_frames
    )
  
  summary_list[[clean_sample_id]] <- sample_summary
  
  # --- Network edges and coords
  edge_list <- which(cor_mat > correlation_threshold & upper.tri(cor_mat), arr.ind = TRUE)
  edges <- data.frame(
    from = rownames(cor_mat)[edge_list[, 1]],
    to   = rownames(cor_mat)[edge_list[, 2]],
    corr = cor_mat[edge_list]
  )

  # get range of corr for color scaling
  valid_corr_vals <- cor_mat[upper.tri(cor_mat) & is.finite(cor_mat)]
  min_corr <- min(valid_corr_vals, na.rm = TRUE)
  max_corr <- 1
  #max_corr <- max(valid_corr_vals, na.rm = TRUE)
  
  edges$corr_scaled <- scales::rescale(edges$corr, to = c(1, 100), from = c(min_corr, max_corr))
  edges$corr_scaled <- pmin(pmax(round(edges$corr_scaled), 1), 100)
  edges$color <- corr_palette[edges$corr_scaled]
  write.csv(edges, file.path(output_dir, "edge_list_with_colors.csv"), row.names = FALSE)

  coords <- df_sample %>%
    dplyr::filter(!is.na(centroid_x), !is.na(centroid_y)) %>%
    dplyr::group_by(ObjectNumber) %>%
    dplyr::slice(1) %>%
    dplyr::ungroup() %>%
    dplyr::distinct(ObjectNumber, centroid_x, centroid_y) %>%
    dplyr::mutate(Label = as.character(ObjectNumber))

  spike_rates <- df_sample %>%
    dplyr::group_by(ObjectNumber) %>%
    dplyr::summarise(spike_rate = mean(dF_F_binary, na.rm = TRUE)) %>%
    dplyr::mutate(Label = as.character(ObjectNumber))

  coords <- dplyr::left_join(coords, spike_rates, by = "Label") %>%
    dplyr::mutate(
      color_idx = pmin(pmax(round(scales::rescale(spike_rate, to = c(1, 100))), 1), 100),
      color = node_palette[color_idx]
    )

  # --- Plotting wrapper
  plot_network <- function(node_colors, edge_colors, legend_title, legend_range, file_name) {
    pdf(file.path(output_dir, file_name), width = 6.9, height = 5)
    layout(matrix(c(1, 2), nrow = 1), widths = c(5, 1.5))
    par(mar = c(4, 4, 2, 1))
    plot(coords$centroid_x, coords$centroid_y,
         pch = 21, bg = node_colors, col = "grey50",
         xlab = "X", ylab = "Y", main = clean_sample_id,
         asp = 1, xlim = c(0, image_dim[1]), ylim = c(0, image_dim[2]))
    for (i in seq_len(nrow(edges))) {
      p1 <- dplyr::filter(coords, Label == edges$from[i])
      p2 <- dplyr::filter(coords, Label == edges$to[i])
      if (nrow(p1) == 1 && nrow(p2) == 1) {
        segments(p1$centroid_x, p1$centroid_y, p2$centroid_x, p2$centroid_y,
                 col = edge_colors[i], lwd = 1)
      }
    }
    par(mar = c(4, 2, 2, 4))
    legend_img <- as.raster(matrix(rev(corr_palette), ncol = 1))
    plot(NA, xlim = c(0, 1), ylim = legend_range, type = "n", axes = FALSE, xlab = "", ylab = "")
    rasterImage(legend_img, 0, legend_range[1], 1, legend_range[2])
    axis(4, at = pretty(legend_range), las = 1)
    mtext(legend_title, side = 4, line = 2.5)
    dev.off()
  }

  # --- Network Plots
  plot_network(rep("grey50", nrow(coords)), edges$color, "Correlation", c(min_corr, max_corr), "network_from_centroids.pdf")
  plot_network(coords$color, edges$color, "Spike rate", c(min_corr, max_corr), "network_from_centroids_spikerate.pdf")

  # --- Save data
  write.csv(firing_stats, file.path(output_dir, paste0(clean_sample_id, "_firing_stats.csv")), row.names = FALSE)
  write.csv(df_sample,     file.path(output_dir, paste0(clean_sample_id, "_df_processed.csv")), row.names = FALSE)
  
  # --- Save correlation matrix (long format)
  cor_long <- as.data.frame(as.table(cor_mat)) %>%
    dplyr::rename(from = Var1, to = Var2, corr = Freq) %>%
    dplyr::mutate(Sample = sample_id) %>%
    dplyr::filter(from != to)
  cor_list[[clean_sample_id]] <- cor_long
  
  # --- Community detection
  g <- igraph::graph_from_data_frame(edges, directed = FALSE)
  
  if (igraph::gorder(g) > 0 && igraph::gsize(g) > 0) {
    comms <- igraph::cluster_louvain(g)
    membership <- membership(comms)
    community_sizes <- sizes(comms)
  
    membership_df <- data.frame(
      ObjectNumber = names(membership),
      Community = membership,
      Sample = sample_id,
      CommunitySize = as.integer(community_sizes[as.character(membership)])
    )
  
    comm_list[[clean_sample_id]] <- membership_df
  }
}




#dev.off()


```





## IId. Save combined Outputs & Sample-Level Normalized Outputs
```{r}
# -----------------------------
# Save Combined Outputs
# -----------------------------
write.csv(bind_rows(cor_list),    file.path(ca_results_dir, "combined_cell_pairwise_correlations.csv"), row.names = FALSE)
write.csv(bind_rows(comm_list),   file.path(ca_results_dir, "combined_cell_community_membership.csv"),  row.names = FALSE)
write.csv(bind_rows(events_list), file.path(ca_results_dir, "combined_events_per_min_results.csv"),     row.names = FALSE)


# ----------------------------------------------------------------------
# Save sample‑level, normalized metrics
# ----------------------------------------------------------------------
normalised_metrics <- bind_rows(summary_list)

write.csv(normalised_metrics,
          file.path(ca_results_dir,
                    "combined_sample_level_normalised_metrics.csv"),
          row.names = FALSE)


```




# III.  Plotting & Statistical Evaluation
## IIIa. ROI Couting and Event Rates Calculation 
```{r}
## ---------------------------------------------------------------------------
##  Plot cellposeSAM/CNER results  –incl. events per min^-1 (±SEM)
## ---------------------------------------------------------------------------

## helper: bind & be sure a “Sample” column exists ---------------------------
bind_with_sample <- function(lst) {
  ## imap_dfr() gives you each element (.x) *and* its list name (.y)
  imap_dfr(lst, ~ {
    if (!"Sample" %in% names(.x))
      .x <- mutate(.x, Sample = .y)  # add from list‑element name
    .x
  })
}

# ----------------------------------------------------------------------
# collapse lists to data‑frames (guaranteed to have ‘Sample’)
# ----------------------------------------------------------------------
events_df <- bind_with_sample(events_list)
comm_df   <- bind_with_sample(comm_list)

# sanity‑check ―now TRUE
stopifnot("Sample" %in% names(events_df),
          "Sample" %in% names(comm_df))

# ----------------------------------------------------------------------
# add genotype label
# ----------------------------------------------------------------------
add_genotype <- function(df, genotype_map) {
  sorted_keys <- names(genotype_map)[order(nchar(names(genotype_map)), decreasing = TRUE)]

  df %>%
    dplyr::mutate(Genotype = purrr::map_chr(.data[["Sample"]], function(s) {
      matched <- sorted_keys[stringr::str_detect(s, fixed(sorted_keys))]
      if (length(matched) > 0) genotype_map[[matched[1]]] else NA_character_
    }))
}
events_df <- add_genotype(events_df, genotype_map)
comm_df   <- add_genotype(comm_df, genotype_map)
normalised_metrics <- add_genotype(normalised_metrics, genotype_map)
#dat <- add_genotype(dat, genotype_map)

# ----------------------------------------------------------------------
# ROI count & calculation of (un)normalised firing–rate
# ----------------------------------------------------------------------

events_df <- events_df %>% 
  group_by(Sample) %>% 
  mutate(
    n_labels          = n(),                             # ROI count
    events_per_min    = firing_events /
                        (total_frames / (frame_rate * 60)),
    events_per_min_norm = events_per_min / n_labels
  ) %>% 
  ungroup()

unique_genos <- unique(c(events_df$Genotype, comm_df$Genotype))
geno_cols <- setNames(colorRampPalette(base_colors)(length(unique_genos)), unique_genos)



```



## IIIb. Scatterplots / Violinplots with SEM (per genotype)
```{r}
# ----------------------------------------------------------------------
# Helper function: plotting violinplot with scatter+SEM error‑bars
# ----------------------------------------------------------------------
plot_metric <- function(dat, metric, ylab, outfile, base_dir) {
  require(ggpubr)

  # --- check that metric exists
  if (!metric %in% names(dat)) {
    stop(paste("Metric", metric, "not found in data"))
  }

  metric_sym <- rlang::sym(metric)

  # --- Ensure factor order
  dat <- dat %>%
    mutate(Genotype = factor(Genotype,
                             levels = unique(unname(genotype_map))))

  # --- Group stats
  mean_dat <- dat %>%
    group_by(Genotype) %>%
    summarise(
      mean_val = mean(!!metric_sym, na.rm = TRUE),
      sem      = sd(!!metric_sym, na.rm = TRUE) / sqrt(n()),
      .groups  = "drop"
    )

  # --- Calculate ANOVA
  aov_model <- aov(as.formula(paste0(metric, " ~ Genotype")), data = dat)
  aov_pval  <- summary(aov_model)[[1]][["Pr(>F)"]][1]

  # --- Pairwise comparisons
  filtered_dat <- dplyr::filter(dat, !is.na(!!metric_sym))
  pw <- pairwise.t.test(filtered_dat[[metric]], filtered_dat$Genotype, p.adjust.method = "holm")

  if (!is.null(pw$p.value)) {
    pairwise_df <- as.data.frame(as.table(pw$p.value), stringsAsFactors = FALSE) %>%
      dplyr::filter(!is.na(Freq) & Freq < 0.05) %>%
      dplyr::rename(group1 = Var1, group2 = Var2, p.value = Freq)

    if (nrow(pairwise_df) > 0) {
      pairwise_df <- pairwise_df %>%
        mutate(
          y.position = seq(from = max(dat[[metric]], na.rm = TRUE) * 1.05,
                           by   = max(dat[[metric]], na.rm = TRUE) * 0.05,
                           length.out = n()),
          p.adj = signif(p.value, 2),
          group1 = factor(group1, levels = levels(dat$Genotype)),
          group2 = factor(group2, levels = levels(dat$Genotype))
        )
    }
  } else {
    pairwise_df <- tibble(group1 = character(), group2 = character(), p.value = numeric())
  }

  # --- Plot violin plot 
p <- ggplot(dat, aes(x = Genotype, y = !!metric_sym, fill = Genotype)) +
  geom_jitter(color = "grey80", width = 0.1, size = 0.5, alpha = 0.5) +
  geom_violin(scale = "width", trim = FALSE, color = NA, width = 0.85, adjust = 1.5) +
  geom_boxplot(width = 0.2, fill = "white", outlier.shape = NA, color = "black", linewidth = 0.3) +
  scale_fill_manual(values = geno_cols) +
  labs(y = ylab, x = NULL) +
  theme_bw(base_size = 6) +
  theme(legend.position = "none",
        aspect.ratio = 2,
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.text.x = element_text(angle = 90, hjust = 0.5)
        )

  
  # --- Add pairwise significance bars
  if (nrow(pairwise_df) > 0) {
    p <- p + stat_pvalue_manual(pairwise_df,
                                label = "p.adj",
                                y.position = "y.position",
                                xmin = "group1",
                                xmax = "group2",
                                tip.length = 0.01,
                                size = 2,
                                inherit.aes = FALSE)
  }

  # --- Save plot
  ggsave(file.path(ca_results_dir, paste0(outfile, ".pdf")),
         p, width = 2, height = 5, device = cairo_pdf)

  # --- Return plot + pvals
  list(
    plot = p,
    pval = bind_rows(
      tibble(Metric = metric, group1 = "ANOVA", group2 = "", p.value = aov_pval),
      pairwise_df %>% mutate(Metric = metric) %>%
        select(Metric, group1, group2, p.value)
    )
  )
}

# ---------------------------------------------------------------------------
# Save general, per‑cell metrics
# ---------------------------------------------------------------------------
# Capture p-values for Export
p_fire_orig_result   <- plot_metric(events_df, "firing_events", "Firing Events", "fire_events", ca_results_dir)
p_active_orig_result <- plot_metric(events_df, "percent_active", "% Active Frames", "percent_active", ca_results_dir)
p_amp_orig_result    <- plot_metric(events_df, "spike_amplitude", "Spike Amplitude", "spike_amplitude", ca_results_dir)

# extract plots
p_fire_orig   <- p_fire_orig_result$plot
p_active_orig <- p_active_orig_result$plot
p_amp_orig    <- p_amp_orig_result$plot



```


## IIIc. Sample-Level Normalized Metrics
```{r}
# ---------------------------------------------------------------------------
# Sample‑level normalised metrics from `normalised_metrics`
# ---------------------------------------------------------------------------

p_fire_norm_result <- plot_metric(normalised_metrics,
                                  "Firing_events_per_min_norm",
                                  "Events · min⁻¹ / ROI",
                                  "fire_events_norm", ca_results_dir)

p_active_norm_result <- plot_metric(normalised_metrics,
                                    "Mean_percent_active_frames_norm",
                                    "% Active / ROI",
                                    "percent_active_norm", ca_results_dir)

p_fire_norm   <- p_fire_norm_result$plot
p_active_norm <- p_active_norm_result$plot


```



## IIId. Community Size Analysis & ANOVA tests 
```{r}
# ---------------------------------------------------------------------------
# Community‑size plot with ANOVA + pairwise stats
# ---------------------------------------------------------------------------
comm_df <- add_genotype(comm_df, genotype_map) %>%
  mutate(Genotype = factor(Genotype, levels = unique(unname(genotype_map))))

comm_df <- comm_df %>%
  mutate(CommunitySize = as.numeric(CommunitySize))

comm_dat <- comm_df %>%
  group_by(Genotype) %>%
  summarise(mean_size = mean(CommunitySize, na.rm = TRUE),
            sem       = sd(CommunitySize, na.rm = TRUE) / sqrt(n()),
            .groups   = "drop")

# --- Global ANOVA
comm_aov <- aov(CommunitySize ~ Genotype, data = comm_df)
comm_aov_pval <- summary(comm_aov)[[1]][["Pr(>F)"]][1]

# --- Pairwise comparisons
comm_pw <- pairwise.t.test(comm_df$CommunitySize, comm_df$Genotype, p.adjust.method = "holm")

if (is.null(comm_pw$p.value)) {
  comm_pw_df <- tibble(group1 = character(0),
                       group2 = character(0),
                       p.value = numeric(0))
} else {
  comm_pw_df <- as.data.frame(as.table(comm_pw$p.value), stringsAsFactors = FALSE) %>%
    dplyr::filter(!is.na(Freq) & Freq < 0.05) %>%
    dplyr::rename(group1 = Var1, group2 = Var2, p.value = Freq)
}

# --- Add y positions and format annotations
if (nrow(comm_pw_df) > 0) {
  comm_pw_df <- comm_pw_df %>%
    mutate(
      y_position = seq(from = max(comm_df$CommunitySize, na.rm = TRUE) * 1.05,
                       by = max(comm_df$CommunitySize, na.rm = TRUE) * 0.05,
                       length.out = n()),
      annotations = signif(p.value, 2)
    )
}

# --- Plot
p_comm <- ggplot(comm_df, aes(x = Genotype, y = CommunitySize, fill = Genotype)) +
  geom_jitter(color = "grey80", width = 0.1, size = 0.5, alpha = 0.5) +
  geom_violin(scale = "width", trim = FALSE, color = NA, width = 0.85, adjust = 1.5) +
  geom_boxplot(width = 0.2, fill = "white", outlier.shape = NA, color = "black", linewidth = 0.3) +
  scale_fill_manual(values = geno_cols) +
  labs(y = "Community Size", x = NULL) +
  theme_bw(base_size = 6) +
  theme(legend.position = "none",
        aspect.ratio    = 2,
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.text.x = element_text(angle = 90, hjust = 0.5)
        )

# --- Add significance brackets manually
if (nrow(comm_pw_df) > 0) {
  comm_pw_df <- comm_pw_df %>%
    mutate(
      y.position = seq(from = max(comm_df$CommunitySize, na.rm = TRUE) * 1.05,
                       by = max(comm_df$CommunitySize, na.rm = TRUE) * 0.05,
                       length.out = n()),
      p.adj = signif(p.value, 2),
      group1 = factor(group1, levels = levels(comm_df$Genotype)),
      group2 = factor(group2, levels = levels(comm_df$Genotype))
    )

  p_comm <- p_comm +
    stat_pvalue_manual(comm_pw_df,
                       label = "p.adj",
                       y.position = "y.position",
                       xmin = "group1",
                       xmax = "group2",
                       tip.length = 0.01,
                       size = 2,
                       inherit.aes = FALSE)
}

# --- Save
ggsave(file.path(ca_results_dir, "plot_community_size.pdf"),
       p_comm, width = 2, height = 3, device = cairo_pdf)


```

## IIIe. Time-binned Firing Metrics Over Time
```{r}
# -------------------------------------------------
# IIIf. Time-binned Firing Metrics Over Time
# -------------------------------------------------

bin_size <- baseline_window  # Use consistent bin size across analysis

# Combine traces and add genotype
traces_with_genotype <- combined_df %>%
  dplyr::left_join(centroid_df, by = c("file", "ObjectNumber")) %>%
  dplyr::mutate(Bin = floor(ImageNumber / bin_size)) %>%
  dplyr::mutate(Genotype = purrr::map_chr(file, function(s) {
    matched <- names(genotype_map)[stringr::str_detect(s, fixed(names(genotype_map)))]
    if (length(matched) > 0) genotype_map[[matched[1]]] else NA_character_
  })) %>%
  dplyr::filter(!is.na(Genotype))  # Remove unmatched genotypes

# Calculate metrics per cell per bin
binned_metrics <- traces_with_genotype %>%
  dplyr::group_by(file, ObjectNumber, Bin, Genotype) %>%
  dplyr::arrange(ImageNumber, .by_group = TRUE) %>%
  dplyr::mutate(
    dF_F = calculate_dff(Intensity_IntegratedIntensity_Fura,
                         window = baseline_window,
                         smoothing_k = smoothing_k,
                         percentile = 0.2),
    dF_F_scaled = dF_F / max(dF_F, na.rm = TRUE),
    dF_F_binary = ifelse(dF_F > threshold_factor * sd(dF_F, na.rm = TRUE), 1, 0),
    spike_amplitude = ifelse(dF_F_binary == 1, dF_F_scaled, NA)
  ) %>%
  dplyr::mutate(rising_edge = dF_F_binary == 1 & dplyr::lag(dF_F_binary, default = 0) == 0) %>%
  dplyr::summarise(
    firing_events = sum(rising_edge, na.rm = TRUE),
    total_frames = dplyr::n(),
    percent_active = 100 * sum(dF_F_binary, na.rm = TRUE) / total_frames,
    spike_amplitude = mean(spike_amplitude, na.rm = TRUE),
    .groups = "drop"
  )

# Summarize per genotype and bin
plot_df <- binned_metrics %>%
  dplyr::group_by(Genotype, Bin) %>%
  dplyr::summarise(
    mean_events = mean(firing_events, na.rm = TRUE),
    sem_events  = sd(firing_events, na.rm = TRUE) / sqrt(dplyr::n()),
    mean_active = mean(percent_active, na.rm = TRUE),
    sem_active  = sd(percent_active, na.rm = TRUE) / sqrt(dplyr::n()),
    mean_amp    = mean(spike_amplitude, na.rm = TRUE),
    sem_amp     = sd(spike_amplitude, na.rm = TRUE) / sqrt(dplyr::n()),
    .groups = "drop"
  )

# Plot helper
plot_timecourse <- function(data, metric, sem, ylab, outfile) {
  ggplot(data, aes(x = Bin * bin_size, y = .data[[metric]], color = Genotype)) +
    geom_line(linewidth = 0.5) +
    geom_ribbon(aes(ymin = .data[[metric]] - .data[[sem]],
                    ymax = .data[[metric]] + .data[[sem]],
                    fill = Genotype), alpha = 0.3, color = NA) +
    labs(x = "Frame", y = ylab) +
    scale_color_manual(values = geno_cols) +
    scale_fill_manual(values = geno_cols) +
    theme_bw(base_size = 6) +
    theme(
      panel.grid = element_blank(),
      axis.text.x = element_text(angle = 90, hjust = 0.5),
      legend.position = "right")
}

# Generate plots
p_bin_events  <- plot_timecourse(plot_df, "mean_events", "sem_events", "Firing Events", "binned_firing_events")
p_bin_active  <- plot_timecourse(plot_df, "mean_active", "sem_active", "% Active Frames", "binned_percent_active")
p_bin_amp     <- plot_timecourse(plot_df, "mean_amp", "sem_amp", "Spike Amplitude", "binned_spike_amplitude")

# Save plots
ggsave(file.path(ca_results_dir, "plot_time_binned_firing_events.pdf"),  p_bin_events, width = 3, height = 2.5, device = cairo_pdf)
ggsave(file.path(ca_results_dir, "plot_time_binned_percent_active.pdf"), p_bin_active, width = 3, height = 2.5, device = cairo_pdf)
ggsave(file.path(ca_results_dir, "plot_time_binned_spike_amplitude.pdf"), p_bin_amp,  width = 3, height = 2.5, device = cairo_pdf)



```


## IIIf. Combined Summary Figure & export of all values 
```{r}
# ---------------------------------------------------------------------------
# Create combined six‑panel figure
# ---------------------------------------------------------------------------
neuro_combinedplot <-
  ((p_fire_norm | p_active_norm | p_amp_orig) /
   (p_bin_amp | p_bin_events | p_comm    )) +
  plot_layout(heights = c(1, 1)) &
  theme(plot.margin = margin(5, 10, 5, 10))

ggsave(file.path(ca_results_dir, "neuro_combinedplot.pdf"),
       neuro_combinedplot, width = 12, height = 12, device = cairo_pdf)

# ---------------------------------------------------------------------------
# Combine and save all stat. values 
# ---------------------------------------------------------------------------

# Save All P-values in csv file in prev. defined outdir 
all_pvals <- bind_rows(
  p_fire_orig_result$pval,
  p_active_orig_result$pval,
  p_amp_orig_result$pval,
  p_fire_norm_result$pval,
  p_active_norm_result$pval,
  bind_rows(
  tibble(Metric = "CommunitySize", group1 = "ANOVA", group2 = "", p.value = comm_aov_pval),
  comm_pw_df %>% mutate(Metric = "CommunitySize") %>%
    select(Metric, group1, group2, p.value)
  )
)


all_pvals <- all_pvals %>%
  select(Metric, group1, group2, p.value)


write.csv(all_pvals,
          file = file.path(ca_results_dir, "calcium_metrics_pvals.csv"),
          row.names = FALSE)

```
